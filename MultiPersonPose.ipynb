{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c3e1b3-35e0-4aa5-b116-b55fd7540578",
   "metadata": {},
   "source": [
    "# Deep Learning Multi-Person Pose Detection for Sport Training Assistance | FGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd34990-768f-4948-ac88-e36df148e208",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b0632e9-0200-45b0-97ff-678d4f5e86b1",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Avoiding OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb3c23-32f6-41dc-9ea0-0332123ffc85",
   "metadata": {},
   "source": [
    "## 1. Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85c22624-854c-4f28-a058-33a0b2f6432f",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a4a34-2758-47db-a26a-5dc8a7594128",
   "metadata": {},
   "source": [
    "## 2. Make Pose Detections using the imported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c746cb7-0568-4437-98d3-56b2b92985a0",
   "metadata": {
    "scrolled": true,
    "tags": [],
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('multiple-football.mp4') # establishes connection to computer webcam with '0' or to a specified video file\n",
    "while cap.isOpened(): # read the current frame that the video is at using cap.read, and unpack the result that we get from that.\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Resize image\n",
    "    img = frame.copy()\n",
    "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 352,640)  # We should be adapting the aspect ratio -> it always has to be 256 or above\n",
    "    input_img = tf.cast(img, dtype=tf.int32)\n",
    "    \n",
    "    # Detecting keypoints\n",
    "    results = movenet(input_img)\n",
    "    # Reshaping given results array and only getting 51 results, as it is the max amount the model can support\n",
    "    keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3)) \n",
    "    \n",
    "    # Rendering keypoints\n",
    "    loop_through_people(frame, keypoints_with_scores, EDGES, 0.3) # We can play with the confidence interval\n",
    "    \n",
    "    cv2.imshow('Movenet Multipose', frame)\n",
    "    \n",
    "    # When we want to exit, once the 'q' key is pressed, user will exit the frame.\n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfd77ec8-1918-4950-a261-5f7c9e0e7e0d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36133632, 0.48715168, 0.54929507],\n",
       "       [0.3276042 , 0.51682925, 0.59449834],\n",
       "       [0.3321823 , 0.44803804, 0.8292286 ],\n",
       "       [0.35596773, 0.56001365, 0.6975824 ],\n",
       "       [0.37167224, 0.40303975, 0.7830701 ],\n",
       "       [0.5121195 , 0.66822916, 0.9037209 ],\n",
       "       [0.51122415, 0.31783044, 0.8294932 ],\n",
       "       [0.73503214, 0.7720009 , 0.4944589 ],\n",
       "       [0.73622394, 0.24371259, 0.7364807 ],\n",
       "       [0.75935453, 0.7908059 , 0.05407606],\n",
       "       [0.7857433 , 0.24542014, 0.03278195],\n",
       "       [0.7795456 , 0.62658995, 0.32489312],\n",
       "       [0.7779475 , 0.3909648 , 0.25077456],\n",
       "       [0.7554027 , 0.78384995, 0.16993205],\n",
       "       [0.75725466, 0.26078653, 0.05835774],\n",
       "       [0.7747849 , 0.5441537 , 0.05672367],\n",
       "       [0.75934917, 0.59486985, 0.05471556]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can see the confident scores from each of the 17 detection points.\n",
    "# Notice that the last 8 rows/detection points give a low confident score\n",
    "# This due to these parts not appearing in the screen as I'm only the computer webcam\n",
    "# Detection points not seen in the screen are 'right ankle, left ankle, right knee, \n",
    "# left knee, right hip, left hip, right wrist, and left wrist.\n",
    "# Note: 1st column -> frame, 2nd column -> keypoints, 3rd column -> confidence threshold\n",
    "keypoints_with_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc288dd8-9eb1-4610-9312-7be69f70fa4e",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Function to loop through each person detected and render detections\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    for person in keypoints_with_scores:\n",
    "        # calling the two rendering functions\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f1703-43fc-43fc-8a88-80c16d5986cd",
   "metadata": {},
   "source": [
    "## 3. Drawing KeyPoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac327313-de59-49fc-b1d3-00048888fc85",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 4, (0,255,0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b807d172-53f5-432f-b231-95a33e612f89",
   "metadata": {},
   "source": [
    "## 4. Drawing Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff06f0c-4e45-4103-b88a-6d0161e8a2d9",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "EDGES = {\n",
    "    (0,1): 'm',\n",
    "    (0,2): 'c',\n",
    "    (1,3): 'm',\n",
    "    (2,4): 'c',\n",
    "    (0,5): 'm',\n",
    "    (0,6): 'c',\n",
    "    (5,7): 'm',\n",
    "    (7,9): 'm',\n",
    "    (6,8): 'c',\n",
    "    (8,10): 'c',\n",
    "    (5,6): 'y',\n",
    "    (5,11): 'm',\n",
    "    (6,12): 'c',\n",
    "    (11,12): 'y',\n",
    "    (11,12): 'm',\n",
    "    (13,15): 'm',\n",
    "    (12,14): 'c',\n",
    "    (14,16): 'c',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9227ae62-1d80-46db-b5e7-3ccb9529b518",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):\n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)),  (0,0,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d3bde-899d-43e2-9527-6f0530c6842d",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MultiPersonPose",
   "language": "python",
   "name": "multipersonpose"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
